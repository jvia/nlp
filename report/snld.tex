
\documentclass[12pt]{article}
\usepackage{times}
\usepackage{latexsym}
\usepackage{xspace}
\usepackage{times}
\usepackage{epsfig}
\setlength{\topmargin}{0 mm}
\setlength{\headsep}{0 mm}
\setlength{\headheight}{0 in}
\setlength{\voffset}{0 mm}
\setlength{\oddsidemargin}{0 mm}
\setlength{\evensidemargin}{0 mm}
\setlength{\hoffset}{0 mm}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{9 in}

\title{Introspection Guided Dialogue-Based Task Resolution}
\author{Jeremiah Via}

\begin{document}
\maketitle

\begin{abstract}
  Situated task-based dialogue poses many challenges for traditional
  natural language understanding techniques. Key among these are
  ambiguous reference resolution, incomplete utterances, task-specific
  utterances. This paper presents a probabilistic belief framework for
  dealing with these challenges. By representing beliefs about the
  world, the agent's own capabilities, and the capabilities of other
  agents in the environment, a dialogue manager can choose actions
  which have the highest likelihood of increasing common ground. A
  probabilistic approach has the additional benefit of remaining
  robust to contradictions, allowing the dialogue manager to simply
  update its probabilities.
\end{abstract}

\section{Introduction}
\label{sec:intro}
In situated contexts, natural language takes on a different set of
characteristics than it does in the form in which it is typically
studied---namely prose. This makes much research not fully-applicable
to situated contexts, where natural language understanding software
must deal with various types of disfluency, common-ground alignment,
and response-time requirements \cite{Scheutz2011:dialogue}. For this
particular project, the problem of ambiguous referents, ungrammatical
sentences, and incrementality were studied. A probabilistic belief
framework was designed to exploit situatedness to better handle these
challenges.

During natural dialogue, ambiguous referents are almost certain to
appear. 

% Key points: algorithm uses probabilistic belief, making it more robust
% to the problems posed by situatedness. depending on its confidence
% about beliefs, it asks questions it believes will yield the most
% information to the interlocutor it believes can yield the most
% information.



% From Matthias' notes:
% \begin{itemize}
% \item Ambiguities
%   \begin{itemize}
%   \item Syntactic ambiguity: “right next to the doorway on the left on the floor” (and ambiguous confirmation “towards the second room”)
%   \item Prosody-based confirmation: “yeah that doorway” (without knowing whether the director got it right)
%   \item Repeated confirmation: “okay”, “um okay” (nothing new)
%   \end{itemize}
% \item Multi-phrase expressions
%   \begin{itemize}
%   \item Sentence instead of referent: “the – so I went ...” (also, not
%     clear when sentence ends, i.e., where the “on the bookshelf in the
%     corner of the room” belongs)
%   \item Cognitive pauses: “uh” and “um” (to gain time)
%   \item Assumption about map: “on the bookshelf in the corner” (there
%     is only one, corner does not have to be specified)
%   \end{itemize}
% \item Omissions
%   \begin{itemize}
%   \item Omissions and insertions: “uh I guess” inserted, “on” and
%     “you” omitted
%   \item Task-based reference: “put one in” and “that's all of them”
%     (assumes “yellow block”)
%   \item Contraction: “all of them you have” (not about “having” them,
%     but about “having put them in pink boxes” )
%   \end{itemize}
% \item Task knowledge
%   \begin{itemize}
%   \item Superfluous words: “like” without meaning, omit for parsing and interpretation
%   \item Perspective-taking: “the first room” or “keep going straight” (assumes knowledge of the other's orientation or position in the world)
%   \item Task goals: “unless you see anything” (assumes knowledge of the task; clearly, “anything” does not mean “anything”, it means “green box” or “blue box” based on the task instructions)
%   \end{itemize}
% \end{itemize}

% ungrammatical sentences (incomplete referential phrases, missing
% verbs, corrections, ...)

% wrong word substitutions for intended target words (“block” and
% “book” for “box”)

% underspecified directions, referents, and directives (assumes shared
% task-knowledge, knowledge of subgoals, perspectives, etc.)

%  lots of “ums and “uhs” indicating cognitive load

%  lots of coordinating “okays” (at least three different kinds can be distinguished by prosody: for acknowledgment of understanding, for requesting expansion, and for acknowledgment of completed action)

%  automatic gesturing and pointing by the member (even though the director being able to see the member)

%  information about meaning encoded in timing of utterances


To overcome these difficulties, a belief manager using a probabilistic
belief representation is proposed.

The rest of the paper is organized as follows. Section
\ref{sec:scenaro} introduces the scenario used for this
project. Particular attention will be paid to the real-world aspects
of the domain that make traditional natural language
understanding. This scenario will motivate the necessity of exploiting
the embodied nature of the robot and its situatedness for improved
performance in this kind of environment. Section \ref{sec:framework}
will describe the approach used with respect to the problem
domain. Particular difficulties of task-based dialogue will be used as
examples against the idea to show how performance improves. In section
\ref{sec:experiments}, a set of experimental results will be shown and
in \ref{sec:analysis} an analysis of the approach will be made.

\section{Scenario/Task description}
\label{sec:scenaro}
% Describe the scenario/task that you are considering in detail
For this task, a robot is placed in an office environment with a
communication link to two human agents, known as \textit{cmdrX} and
\textit{cmdrY}. The goal of this task is for the robot to locate a
specific medical kit. No one agent has complete knowledge of the
environment or task, nor is this knowledge guaranteed to be accurate.
As a further difficulty, there are multiple medical kits in the
office, and a specific one must be determined for the task to be
completed. Key to this task are the inter-mixing of dialogue and
physical action, underspecified instructions, and belief revision.

% make reference to all the sources you used and inform the reader
% about possible strategies for developing algorithms for the task
The robot has beliefs about the usual location of these kinds of
medical kits, but when reality fails to meet expectations, it must
gather information from two interlocutors participating in the
task. Neither interlocutor has full knowledge of the task and so the
robot must direct the conversation such that it can maximize its
knowledge related to the task.

% Describe the task and possible solutions, and point out their
% advantages and disadvantages
One approach to dialogue management is the use of a
partially-observable Markov decision process (POMDP). It has these
benefits\dots. It is unsuitable for this task...

Rule-based approaches are also common\dots.
% You should not repeat details of well-known algorithms; instead just
% refer to them where appropriate (e.g., to the literature used in
% class) You may assume that the reader has some knowledge about
% situated natural language processing

\section{An Introspective Belief Framework}
\label{sec:framework}
% Describe in detail your solution to the problem, possibly including
% graphs and figures to aid the reader Include detailed descriptions of
% your the algorithm and how the situated context is utilized to make
% parts of the NL chain work better (this is critical and should be the
% highlight of the paper)

To handle the challenges previously outlined, an introspective
framework utilizing probabilistic beliefs was developed. Central to
this idea was a constantly changing set of beliefs. The goal of the
agent was to minimize the entropy of its beliefs with respect to the
task. This belief structure was used to augment a simple, rule-based
dialogue manager, allowing it reach conclusions otherwise not
possible.

More detail about the solution goes here\dots.

\subsection{Common Ground}
\begin{verbatim}
cmdrX: find the medkit.
self: the red_medkit or the blu_medkit?
cmdrX: the red_medkit.
self: okay.
\end{verbatim}

\begin{verbatim}
{{:self {:confidence 0.9}
        {:at ...}}
 {:objects [:red_medkit
            :blu_medkit]}
 {:red_medkit {:at :areaA
               :type :medkit}}
 {:blu_medkit {:at :areaC
               :type :medkit}}
...}
\end{verbatim}

\begin{verbatim}
...
 {:referents
  {:medkit :red_medkit}
...
\end{verbatim}
\subsection{Surprise}

\begin{verbatim}
cmdrX: whoa!
cmdrX: what are you doing?
self: going to areaA to find the red_medkit.
cmdrX: the red_medkit is not at areaA.
\end{verbatim}

\begin{verbatim}
{{:self {:confidence 0.9}
        {:at ...}}
 {:objects [:red_medkit
            :blu_medkit]}
 {:red_medkit {:at :areaA
               :type :medkit}}
 {:blu_medkit {:at :areaC
               :type :medkit}}

...}
\end{verbatim}

\begin{verbatim}
...
{:self {:confidence 0.5 :location [[x y z] [x y z w]]}}
{:objects {:red_medkit 0.9 :blu_medkit 0.9}}
{:areaA {:location []}}
{:areaB {:location []}}
{:red_medkit {:at {:areaA 0.8 :areaB 0.1 :areaC 0.1}
             {:type {:medkit 1.0}}
...
\end{verbatim}

\subsection{Entropy Reduction}
\begin{verbatim}
self: where is the red_medkit?
cmdrX: i don't know.
self: cmdrY, where is the red_medkit?
cmdrY: areaB.
self: okay.
\end{verbatim}

\subsection{Experiments and results}
\label{sec:experiments}
% Show experimental data from runs with the integrated system in ADE
% that demonstrate your improvements and how they work

% Compare your results to results without the improvements (this is
% critical because you need to show that without utilizing the
% situatedness of the agent, established algorithms would do worse --
% make sure that you have a clear performance measure defined) Perform
% simple statistics on the results if applicable S

\subsection{Analysis}
\label{sec:analysis}
% Discuss the advantages and possible disadvantages of your algorithm
% Suggest additional experiments and/or improvements to the solution.

\section{Conclusion}
\label{sec:conclusion}
% Summarize what your solution achieved, and how your algoritm could be
% extended or used in other tasks Briefly discuss directions for future
% work.


Utilizing more types of probabilistic distributions would allow for
more robust inference processes. In this study, only a Bernoulii
distribution and the more general Categorical distribution were
used. This is quite limiting when reasoning about objects in space,
e.g., the location of a given medical kit. A better approach would be
to use continuous distributions, perhaps backed by a particle filter.
Another direction would be to direct dialogue to increase common
ground between all agents in the environment. For example, during the
dialogue, after the robotic agent first received the location of the
red medical kit from cmdrX, it could have tried to create common
ground with cmdrY, creating an immediate contradiction between the
beliefs of cmdrX and cmdrY. Dialogue could then pursue a resolution to
this dialogue. A final improvement could be performed during the
grounding of ambiguous referents. In this example, the robot simply
chooses a feature with separate values to attempt to disambiguate the
potential referents. A more natural approach would be to choose the
most salient features of the objects for comparison. This would
require having beliefs about objects and their salient features, but
it is a natural fit for this kind of belief framework.

This paper showed\dots.
\bibliographystyle{apalike} {\small \bibliography{references}}
\end{document}
% LocalWords:  disfluencies disfluency incrementality  cmdrY
% LocalWords:  cmdrX
